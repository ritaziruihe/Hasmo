import requests
from bs4 import BeautifulSoup
import json
import random
import time
import pandas as pd
from openpyxl.styles import Alignment, Border, Side, Font


BASE_URL = "https://www.mckinsey.com"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
EXCLUDE_TEXTS = ["Skip to main content", "Contact", "", "View all", "Read more"]

def random_delay(min_delay=1, max_delay=3):
    time.sleep(random.uniform(min_delay, max_delay))


def clean_text(text):
    text = ' '.join(text.strip().split())  
    return text if text and text not in EXCLUDE_TEXTS else None


def filter_unique(items):
    seen = set()
    return [x for x in items if x and not (x in seen or seen.add(x))]


def fetch_page(url):
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()  
        return response.text
    except requests.exceptions.RequestException as e:
        print(f"请求失败: {url}\n错误详情: {str(e)}")
        return None


def fetch_mckinsey_data():
    print("Starting data scraping...")
    data = {
        'service_offerings': [],
        'case_studies': [],
        'client_testimonials': [],
        'thought_leadership': [],
        'market_insight': []
    }


    ###service_url = BASE_URL + "/locations/mckinsey-client-capabilities-network/our-work"
    service_url = "https://www.mckinsey.com/industries/technology-media-and-telecommunications/how-we-help-clients"
    service_html = fetch_page(service_url)
    if service_html:
        service_soup = BeautifulSoup(service_html, 'html.parser')
        service_links = service_soup.find_all('a')
        data['service_offerings'] = filter_unique([
            clean_text(link.get_text()) for link in service_links
        ])
    random_delay()


    case_url = BASE_URL + "/about-us/case-studies"
    case_html = fetch_page(case_url)
    if case_html:
        case_soup = BeautifulSoup(case_html, 'html.parser')
        case_titles = case_soup.find_all('h5')
        data['case_studies'] = filter_unique([
            clean_text(title.get_text()) for title in case_titles
        ])
    random_delay()


    leadership_url = BASE_URL + "/featured-insights/leadership"
    leadership_html = fetch_page(leadership_url)
    if leadership_html:
        leadership_soup = BeautifulSoup(leadership_html, 'html.parser')
        leadership_titles = leadership_soup.find_all('h5')
        data['thought_leadership'] = filter_unique([
            clean_text(title.get_text()) for title in leadership_titles
        ])
    random_delay()

    client_url = BASE_URL + "/capabilities/growth-marketing-and-sales/how-we-help-clients/impact-stories"
    client_html = fetch_page(client_url)
    if client_html:
        client_soup = BeautifulSoup(client_html, 'html.parser')
        client_testimonials = client_soup.find_all('div', class_="mck-u-links-inline mck-c-generic-item__description")
        data['client_testimonials'] = filter_unique([
            clean_text(testimony.get_text()) for testimony in client_testimonials
        ])
    random_delay()


    market_url = BASE_URL + "/capabilities/growth-marketing-and-sales/how-we-help-clients/insights-and-analytics"
    market_html = fetch_page(market_url)
    if market_html:
        market_soup = BeautifulSoup(market_html, 'html.parser')
        market_insights = market_soup.find_all('p')
        data['market_insight'] = filter_unique([
            clean_text(insight.get_text()) for insight in market_insights
        ])
    random_delay()


    print(json.dumps(data, indent=4, ensure_ascii=False))
    return data


def style_excel_sheet(sheet):

    sheet.column_dimensions['A'].width = 50


    title_font = Font(bold=True, size=14)
    title_alignment = Alignment(horizontal='center', vertical='center')
    for cell in sheet[1]:
        cell.font = title_font
        cell.alignment = title_alignment


    border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    for row in sheet.iter_rows():
        for cell in row:
            cell.border = border


def save_to_excel(data, filename="mckinsey_data.xlsx"):
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        for category, items in data.items():
            df = pd.DataFrame({category: items})
            df.to_excel(writer, sheet_name=category[:31], index=False)
        metadata = {
            'Last Updated': [pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')],
            'Total Categories': [len(data)],
            'Total Items': [sum(len(v) for v in data.values())]
        }
        pd.DataFrame(metadata).to_excel(writer, sheet_name='Metadata', index=False)

    workbook = writer.book
    for sheet_name in workbook.sheetnames:
        sheet = workbook[sheet_name]
        style_excel_sheet(sheet)

    print(f"saved {filename}")

if __name__ == "__main__":
    data = fetch_mckinsey_data()
    save_to_excel(data)